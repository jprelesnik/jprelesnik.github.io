# jprelesnik.github.io
Jesse Prelesnik received his BS Biochemistry (2016) from Western Washington University (WWU) magna cum laude, performing undergraduate research under John Antos on the subject of sortase enzyme substrate recognition. He transitioned to computational science during this PhD Chemistry (at the University of Washington (UW), first under Lutz Maibaum receiving a rigorous education in statistical mechanics, molecular dynamics, and enhanced sampling strategies, and later under Jim Pfaendtner where he specialized in metadynamics biasing strategies and joined an Energy Frontiers Research Center (EFRC), the Center for the Science of Synthesis Across Scales (CSSAS). Within this program he did an internship at Pacific Northwest National Laboratory (PNNL) and became co-advised by Chris Mundy, developing far-field electrostatic theories and extracting parameters from classical atomistic simulation results to explain differences in assembly behaviors of designed proteins from the lab of David Baker. After graduating in 2021, Jesse took a postdoctoral research position at the University of Minnesota (UMN) under J. Ilja Siepmann, developing an interest in porous adsorbent materials and expanding his simulation toolkit to include Monte Carlo (MC) methods, namely the Gibbs Ensemble (GEMC) and Transition Matrix (TMMC) varieities. Since 2024, Jesse has been a core postdoc at the Center for Nanoscale Materials (CNM) at Argonne National Laboratory (ANL) in a combined experimental/theoretical effort alongside H. Chris Fry and co-advised by Henry Chan, who provides guidance on AI modeling to connect simulation results to experimental observations. He is seeking a Staff Scientist position at one of the United Stated National Labs.

Jesse's expertise is in an area of chemical physics called statistical mechanics, a branch of probability theory which connects microscopic interactions to macroscopic observables. Through this framework, many thermophysical properties of interest can be predicted from an ensemble of molecular configurations to correctly incorporate fluctuations into the calculation. Classical particle-based simulations are the most popular tool in this field, offering spatiotemporal resolution inaccessible to experiments while affording the computational efficiency needed to sample a myriad of states and provide ample data. His technical expertise is therefore an offshoot of data science, with a strong background in statistical properties, mathematics, algorithm development, and creative design of so-called “collective variables” for dimensionality reduction. In the modern age of computing, there is unprecedented opportunity to leverage these skills for ambitious project designs, with hardware advances enabling accelerated data acquisition experimentally, and software breakthroughs revolutionizing statistical analysis through machine learning (ML). Large collaborations like at National Labs are exemplary for realizing these advances, with powerful supercomputer facilities and expansive synthetic and experimental platforms to connect with predictive modeling efforts.

These studies contribute to emerging nanotechnology efforts with applications in energy storage, capture, and/or conversion, particularly emphasizing my expertise related to adsorption in porous materials (for processes like separations, refrigeration, and water harvesting within materials like metal–organic frameworks (MOFs) and zeolites) and soft matter self-assembly (responsive hierarchical materials with and without substrates). A common theme is the importance of microscopic interfaces that modify molecular behaviors and the way that subtle differences in the attributes of these junctions result in emergent properties. Simulations provide mechanistic insight for unexplained experimental phenomena and aid in materials design by predicting the response properties of nanoscale materials. These energy-focused research directions in mesoscale science are fertile ground for advancement by optimizing thermodynamic and compositional variables for inverse design, a goal he intends to realize with high-throughput data acquisition via autonomous systems and innovative ML. His background in molecular simulation emphasizes identifying high-throughput workflows to contribute data, both architecturally (massively parallel and/or GPU-accelerated) and procedurally, selecting sampling algorithms that converge rapidly. This philosophy extends to ML strategies, making the most of available computer power and experimental output by adapting the model for a data-sparse regime. Such a holistic research approach takes advantage of the strengths from all four pillars of science to learn fundamental processes that inform real-world applications.


